## 音视频与即时通讯业务

### 目录

- 1.音视频
- 2.即时通讯

### 1.音视频

视频封装格式：压缩过的视频数据和音频数据打包成一个文件。MP4/FLV/TS。

视频播放：ijkplayer开源库。基于FFmpeg(官网)开发。FFmpeg：音视频转换和流的传输。FFmpeg音视频的同步：按照视频和音频的时间戳按照时间排序插入队列。实现原理：视频进行压缩编码，解析成一帧一帧，显示在屏幕上。

视频录制：Camera摄像头录制视频类，MediaProjection屏幕录制视频类

视频编码：对视频进行压缩，将原始的视频流压缩成特定的比特流。MediaCodec，MediaRecorder。解码：对编码的视频进行解压缩处理。视频编码-H264/H265/VP9；音频编码-AAC/OPUS。音频：DTS-解码时间戳；PTS-显示时间戳。VideoToolbox:硬编硬解码。

视频预览：SurfaceView,GLSurfaceView,TextureView,VideoView

视频间通信：

- 视频推拉流：需要时间，一对多。一边一个人推流一边很多人在拉流观看，有延时。协议：RTMP-实时消息传输协议。
- WebRTC：实时通信技术，一对一。协议：WHATWG，socket。用途：视频会议。建立通讯流程。
- SIP：信令协议；RTP/RTCP：实时传输协议；RTSP：实时流传输协议；HLS：动态码率自适应技术。
- gstreamer：用来构建流媒体应用的开源多媒体框架(framework)，其目标是要简化音/视频应用程序的开发
- DUILib：一款强大的界面开发工具，可以将用户界面和处理逻辑彻底分离，极大地提高用户界面的开发效率，遵循bsd协议。

**屏幕录制的步骤大概可以总结为：**

1）通过MediaProjectionManager取得向用户申请权限的intent，在onActivityResult()完成对用户动作的响应；

2）用户允许后开始录制，可以直接写在一个Activity里，但是像这样另外写在Service里更为妥当，录制的代码也可以单独抽出来写成一个ScreenRecorder的类；

3）获取MediaProjection的实例，获取及配置MediaRecorder的实例，并记得MediaRecorder需要prepare()；

4）获取VirtualDisplay的实例，它也是MediaProjection, MediaRecorder完成交互的地方，录制的屏幕内容其实就是mediaRecorder.getSurface() 获得的 surface 上的内容。

如果不使用MediaProjection + MediaRecorder组合，也可以使用MediaProjection + MediaCodec + MediaMuxer组合实现相同的功能。其中各个类的作用简要总结如下：

- MediaMuxer:将音频和视频进行混合生成多媒体文件，输出mp4格式；
- MediaCodec：将音视频进行压缩编码，并可以对Surface内容进行编码，实现屏幕录像功能；
- MediaExtrator:将音视频分路，和MediaCodec正好反过程；
- MediaFormat：用于描述多媒体数据的格式；
- MediaRecoder:用于录像并压缩编码，相较于MediaCodec更适合屏幕录像；
- MediaPlayer:用于播放压缩编码后的音视频文件；
- AudioRecord:用于录制PCM数据；
- AudioTrack:用于播放PCM数据；PCM即原始音频采样数据

**视频播放**

视频显示控件：SurfaceView/TextureView

视频编解码：原生mediaplayer/谷歌出的EXOplayer/B站的IJKplayer/各大公司自己写的

### 2.即时通讯(发送-接收消息)

网易云信：uikit库。自己写的协议。

openfire：xmpp协议。







